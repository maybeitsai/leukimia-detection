{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_dataset_split_aug.py\n",
    "# Membagi data 70:30 (train:test), lalu augmentasi hanya training\n",
    "# Output disimpan di data/final/train/ dan data/final/test/\n",
    "\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06fc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# PARAMETER\n",
    "# --------------------------\n",
    "SOURCE_DIR = \"data/Original\"\n",
    "TARGET_DIR = \"data/Final\"\n",
    "IMG_SIZE = (224, 224)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# Augmentasi pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "])\n",
    "\n",
    "def load_and_preprocess(img_path, target_size=IMG_SIZE):\n",
    "    \"\"\"Load image and resize\"\"\"\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_arr = image.img_to_array(img) / 255.0\n",
    "    return img_arr\n",
    "\n",
    "def save_image(arr, save_path):\n",
    "    \"\"\"Save numpy array as image JPG\"\"\"\n",
    "    arr = np.clip(arr * 255.0, 0, 255).astype(np.uint8)\n",
    "    tf.keras.utils.save_img(save_path, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93222d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas ditemukan: ['Benign', 'Early', 'Pre', 'Pro']\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 1. List kelas & file\n",
    "# --------------------------\n",
    "classes = [d for d in os.listdir(SOURCE_DIR) if os.path.isdir(os.path.join(SOURCE_DIR, d))]\n",
    "print(\"Kelas ditemukan:\", classes)\n",
    "\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2d1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 2. Split train:test (70:30)\n",
    "# --------------------------\n",
    "split_ratio = 0.3\n",
    "train_files = {}\n",
    "test_files = {}\n",
    "\n",
    "for cls in classes:\n",
    "    src_folder = Path(SOURCE_DIR) / cls\n",
    "    files = list(src_folder.glob(\"*.jpg\")) + list(src_folder.glob(\"*.png\")) + list(src_folder.glob(\"*.jpeg\"))\n",
    "    \n",
    "    train_f, test_f = train_test_split(files, test_size=split_ratio, random_state=SEED, shuffle=True)\n",
    "    train_files[cls] = train_f\n",
    "    test_files[cls] = test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0896f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menyimpan data train & test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copy train Benign: 100%|██████████| 352/352 [00:01<00:00, 213.56it/s]\n",
      "Copy test Benign: 100%|██████████| 152/152 [00:00<00:00, 231.29it/s]\n",
      "Copy train Early: 100%|██████████| 689/689 [00:02<00:00, 230.87it/s]\n",
      "Copy test Early: 100%|██████████| 296/296 [00:01<00:00, 230.23it/s]\n",
      "Copy train Pre: 100%|██████████| 674/674 [00:02<00:00, 232.31it/s]\n",
      "Copy test Pre: 100%|██████████| 289/289 [00:01<00:00, 231.09it/s]\n",
      "Copy train Pro: 100%|██████████| 562/562 [00:02<00:00, 215.10it/s]\n",
      "Copy test Pro: 100%|██████████| 242/242 [00:01<00:00, 166.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 3. Copy train & test\n",
    "# --------------------------\n",
    "print(\"\\nMenyimpan data train & test...\")\n",
    "for cls in classes:\n",
    "    train_dir = Path(TARGET_DIR) / \"train\" / cls\n",
    "    test_dir = Path(TARGET_DIR) / \"test\" / cls\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for f in tqdm(train_files[cls], desc=f\"Copy train {cls}\"):\n",
    "        img = load_and_preprocess(str(f))\n",
    "        save_path = train_dir / f.name\n",
    "        save_image(img, save_path)\n",
    "\n",
    "    for f in tqdm(test_files[cls], desc=f\"Copy test {cls}\"):\n",
    "        img = load_and_preprocess(str(f))\n",
    "        save_path = test_dir / f.name\n",
    "        save_image(img, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48d967d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmentasi data training...\n",
      "Kelas Benign: 352 gambar, butuh 2648 augmentasi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augment Benign: 100%|██████████| 2648/2648 [04:59<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Benign: total 3000 gambar setelah augmentasi\n",
      "Kelas Early: 689 gambar, butuh 2311 augmentasi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augment Early: 100%|██████████| 2311/2311 [04:23<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Early: total 3000 gambar setelah augmentasi\n",
      "Kelas Pre: 674 gambar, butuh 2326 augmentasi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augment Pre: 100%|██████████| 2326/2326 [04:22<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Pre: total 3000 gambar setelah augmentasi\n",
      "Kelas Pro: 562 gambar, butuh 2438 augmentasi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augment Pro: 100%|██████████| 2438/2438 [04:50<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelas Pro: total 3000 gambar setelah augmentasi\n",
      "\n",
      "Distribusi train akhir: {'Benign': 3000, 'Early': 3000, 'Pre': 3000, 'Pro': 3000}\n",
      "Total train dataset: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 4. Augmentasi data TRAIN\n",
    "# --------------------------\n",
    "print(\"\\nAugmentasi data training...\")\n",
    "target_min = 3000   # minimal per kelas\n",
    "final_target_total = 12000  # minimal total keseluruhan\n",
    "\n",
    "class_counts = {}\n",
    "\n",
    "for cls in classes:\n",
    "    train_dir = Path(TARGET_DIR) / \"train\" / cls\n",
    "    files = list(train_dir.glob(\"*.jpg\")) + list(train_dir.glob(\"*.png\"))\n",
    "    count = len(files)\n",
    "\n",
    "    if count >= target_min:\n",
    "        class_counts[cls] = count\n",
    "        print(f\"Kelas {cls} sudah memenuhi target ({count} gambar)\")\n",
    "        continue\n",
    "\n",
    "    needed = target_min - count\n",
    "    print(f\"Kelas {cls}: {count} gambar, butuh {needed} augmentasi\")\n",
    "\n",
    "    pbar = tqdm(total=needed, desc=f\"Augment {cls}\")\n",
    "\n",
    "    # proses augmentasi batch\n",
    "    imgs = [load_and_preprocess(str(f)) for f in files]\n",
    "    imgs = np.array(imgs)\n",
    "\n",
    "    aug_counter = 0\n",
    "    while aug_counter < needed:\n",
    "        # ambil batch random\n",
    "        batch_idx = np.random.choice(len(imgs), size=32)\n",
    "        batch = imgs[batch_idx]\n",
    "\n",
    "        aug_batch = data_augmentation(batch, training=True).numpy()\n",
    "        for aug_img in aug_batch:\n",
    "            if aug_counter >= needed:\n",
    "                break\n",
    "            save_name = f\"aug_{count + aug_counter + 1:05d}.jpg\"\n",
    "            save_path = train_dir / save_name\n",
    "            save_image(aug_img, save_path)\n",
    "            aug_counter += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    class_counts[cls] = count + needed\n",
    "    print(f\"Kelas {cls}: total {class_counts[cls]} gambar setelah augmentasi\")\n",
    "\n",
    "print(\"\\nDistribusi train akhir:\", class_counts)\n",
    "print(\"Total train dataset:\", sum(class_counts.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a62ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribusi test: {'Benign': 152, 'Early': 296, 'Pre': 289, 'Pro': 242} Total: 979\n",
      "\n",
      "Dataset final tersimpan di: data/Final\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 5. Hitung distribusi test\n",
    "# --------------------------\n",
    "test_counts = {cls: len(test_files[cls]) for cls in classes}\n",
    "print(\"Distribusi test:\", test_counts, \"Total:\", sum(test_counts.values()))\n",
    "\n",
    "print(\"\\nDataset final tersimpan di:\", TARGET_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
